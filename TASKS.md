- allow changing the model midway
- add a /reload command to reload the context
- Allow dropping context pieces. Likely they will need to have some IDs that we'll use.
- Add a /ls command that will list what are the included context pieces.
- Allow LLM to request additional context by writing commands
- Allow showing the costs of the API calls
- Allow configuring models with platform/provider/model?
- Consider using ELL: [MadcowD/ell: A language model programming library.](https://github.com/MadcowD/ell)
- Implemenet cache for context providers
- Allow users configure context they want to include with all prompts - in their config folder
- It is actually quite cool that the notebook writes concerns itself. Maybe make that a feature.
- Add <Gap> only as well
- Graceful handling of model output limit exceptions
- Infinite output support
- Live edit mode - the LLM sees what you edited, understands the diffs history, suggests next steps, understands direction.
- Implement integration tests to run before push
- Same for extensions, have a specific place with a specific variable to import.
- Improve how the filename is sent to the LLM, send original name

# From Feedback
- Add version numbers
- Add version check command
- Allow adding help markdown file in extensions
- Sometimes we get "Chat interrupted by user. Continuing" and it doesn't stop. Seems to be related with pipe in.
- We should allow the user to order the context they are providing. We should not group everything together.
- There should be difference between context pieces that are just for context and the ones that we are actively focused on.
- Some context providers should be stackable - build hierarchy of xml tags
- Ability to go back in history. Nice interface to go up up and enter. Can we track the key inputs? Maybe make some hot keys alongside commands?
- Multi-line is broken
- e.g. the user runs /append multiple times, what happens, how does the history look like
- Add /undo command